# Chapter 5: Large Language Models to Identify Social Determinants of Health in Electronic Health Records

---
*Shan Chen\****, Marco Guevara\*, Spencer Thomas, Tafadzwa L. Chaunzwa, Idalid Franco, Benjamin H. Kann, Shalini Moningi, Jack M. Qian, Madeleine Goldstein, Susan Harper,
Hugo JWL Aerts, Paul J. Catalano, Guergana K. Savova,
Raymond H. Mak, Danielle S. Bitterman

npj Digital Medicine
Summary
Background
SDoH strongly affect outcomes but are poorly captured in structured EHR data. LLMs could extract SDoH from clinical text, but sparse labels, class imbalance, and bias are challenges.
Methods
We evaluated LLMs to extract six SDoH from notes (employment, housing, transportation, parental status, relationship, social support), testing fine-tuned Flan-T5 variants, synthetic-data augmentation, and zero-/few-shot ChatGPT-family baselines, plus a simple bias probe with injected demographics.
Findings
Best models: Flan-T5 **XL** for any SDoH (macro-F1 **0.71**) and Flan-T5 **XXL** for adverse SDoH (macro-F1 **0.70**). Synthetic data helped smaller Flan-T5 models (**ΔF1 \+0.12–+0.23**). Fine-tuned models beat ChatGPT-family zero-/few-shot, except **GPT-4 (10-shot)** on adverse SDoH. Fine-tuned models changed predictions less than ChatGPT when race/ethnicity or gender was injected (**p\<0.05**), indicating less algorithmic bias. At the patient level, models identified **93.8%** with adverse SDoH vs **2.0%** using ICD-10 Z-codes.

Interpretation
Fine-tuned LLMs—augmented with synthetic text—can reliably surface SDoH from EHR notes, outperform general chat models and structured codes, and show lower bias, enabling better real-world evidence and targeted resource support.

## INTRODUCTION

Health disparities have been extensively documented across medical specialties.[1–3](https://paperpile.com/c/yjfVx4/j1dN+8yTi+Zp8L) However, our ability to address these disparities remains limited due to an insufficient understanding of their contributing factors. Social determinants of health (SDoH), are defined by the World Health Organization as “the conditions in which people are born, grow, live, work, and age...shaped by the distribution of money, power, and resources at global, national, and local levels”. [4](https://paperpile.com/c/yjfVx4/9pBzf) SDoH may be adverse or protective, impacting health outcomes at multiple levels as they likely play a major role in disparities by determining access to and quality of medical care. For example, a patient cannot benefit from an effective treatment if they don’t have transportation to make it to the clinic. There is also emerging evidence that exposure to adverse SDoH may directly affect physical and mental health via inflammatory and neuro-endocrine changes.[5–8](https://paperpile.com/c/yjfVx4/HoSYw+VXeKa+dQla1+zvwv7) In fact, SDoH are estimated to account for 80-90% of modifiable factors impacting health outcomes.[9](https://paperpile.com/c/yjfVx4/QlpcC)

SDoH are rarely documented comprehensively in structured data in the electronic health records (EHRs),[10–12](https://paperpile.com/c/yjfVx4/NfPNB+HNP8d+xuWCW) creating an obstacle to research and clinical care. Instead, issues related to SDoH are most frequently described in the free text of clinic notes, which creates a bottleneck for incorporating these critical factors into databases to research the full impact and drivers of SDoH, and for proactively identifying patients who may benefit from additional social work and resource support.

Natural language processing (NLP) could address these challenges by automating the abstraction of these data from clinical texts. Prior studies have demonstrated the feasibility of NLP for extracting a range of SDoH.[13–23](https://paperpile.com/c/yjfVx4/dwSP+QKOo+3Z4R+tPmm+EfrS+v7vl+C5qx+ywEU+1P2G+XEymp+M3kyq) Yet, there remains a need to optimize performance for the high-stakes medical domain and to evaluate state-of-the-art language models (LMs) for this task. In addition to anticipated performance changes scaling with model size, large LMs may support EHR mining via data augmentation. Across medical domains, data augmentation can boost performance and alleviate domain transfer issues and so is an especially promising approach for the nearly ubiquitous challenge of data scarcity in clinical NLP.[24–26](https://paperpile.com/c/yjfVx4/OqrO+59gr+qGZf) The advanced capabilities of state-of-the-art large LMs to generate coherent text open new avenues for data augmentation through synthetic text generation. However, the optimal methods for generating and utilizing such data remain uncertain. Large LM-generated synthetic data may also be a means to distill knowledge represented in larger LMs to more computationally accessible smaller LMs.[27](https://paperpile.com/c/yjfVx4/PbaK) In addition, few studies assess the potential bias of SDoH information extraction methods across patient populations. LMs could contribute to the health inequity crisis if they perform differently in diverse populations and/or recapitulate societal prejudices.[28](https://paperpile.com/c/yjfVx4/RBOwB) Therefore, understanding bias is critical for future development and deployment decisions.

Here, we characterize optimal methods, including the role of synthetic clinical text, for SDoH extraction using large language models. Specifically, we develop models to extract six key SDoH: employment status, housing issues, transportation issues, parental status, and social support. We investigate the value of incorporating large LM-generated synthetic SDoH data during the fine-tuning stage. We assess the performance of large LMs, including GPT3.5 and GPT4, in zero- and few-shot settings for identifying SDoH, and we explore the potential for algorithmic bias in LM predictions. Our methods could yield real-world evidence on SDoH, assist in identifying patients who could benefit from resource and social work support, and draw attention to the under-documented impact of social factors in health outcomes.

![][image19]

**Fig. 1: Ablation studies:** Performance in Macro-F1 of Flan-T5 XL models fine-tuned using gold data only (orange line) and gold and synthetic data (green line), as gold-labeled sentences are gradually reduced by undersample value from the training dataset for **a)** adverse social determinant of health (SDoH) mention task and **b)** any SDoH mention task. The full gold-labeled training set is comprised of 29,869 sentences, augmented with 1800 synthetic SDoH sentences, and tested on the in-domain radiotherapy(RT) test dataset.**

RESULTS
Model performance
*Table 3* shows the performance of fine-tuned models for both SDoH tasks on the radiotherapy test set. The best-performing model for any SDoH mention task was Flan-T5 XXL (3 out of 6 categories) using synthetic data (Macro-F1 0.71). The best-performing model for the adverse SDoH mention task was Flan-T5 XL without synthetic data (macro-F1 0.70). In general, the Flan-T5 models outperformed BERT, and model performance scaled with size. However, although the Flan-T5 XL and XXL models were the largest models evaluated in terms of total parameters, because LoRA was used for their fine-tuning, the fewest parameters were tuned for these models: 9.5M and 18M for Flan-TX XL and XXL, respectively compared to 110M for BERT. The negative class generally had the best performance overall, followed by Relationship and Employment. Performance varied quite a bit across the models for the other classes.

![][image20]

**Fig. 2: Fine-tuned LLMs versus ChatGPT-family models:** Comparison of model performance between our fine-tuned Flan-T5 models against zero- and 10-shot GPT. Macro-F1 was measured using our manually validated synthetic dataset. The GPT-turbo-0613 version of GPT3.5 and the GPT4–0613 version of GPT4 were used. Error bars indicate the 95% confidence intervals. LLM large language model.**

For both tasks, the best-performing models with synthetic data augmentation used sentences from both rounds of GPT3.5 prompting. Synthetic data augmentation tended to lead to the largest performance improvements for classes with few instances in the training dataset and for which the model trained on gold-only data had very low performance (Housing, Parent, and Transportation).

The performance of the best-performing models for each task on the immunotherapy and MIMIC-III datasets are shown in *Table 4**.*** Performance was similar in the immunotherapy dataset, which represents a separate but similar patient population treated at the same hospital system. We observed a performance decrement on the MIMIC-III dataset, representing a more dissimilar patient population from a different hospital system. Performance was similar between models developed with and without synthetic data.

![][image21]

**Fig. 3: LLM bias evaluation:** The proportion of synthetic sentence pairs with and without demographics injected led to a classification mismatch, meaning that the model predicted a different SDoH label for each sentence in the pair. Results are shown across race/ethnicity and gender for a any SDoH mention task and b adverse SDoH mention task. Asterisks indicate statistical significance (P ≤ 0.05) chi-squared tests for multi-class comparisons and 2-proportion z tests for binary comparisons. LLM large language model, SDoH Social determinants of health.**

Ablation studies
The ablation studies showed a consistent deterioration in model performance across all SDoH tasks and categories as the volume of real gold SDoH sentences progressively decreased, although models that included synthetic data maintained performance at higher levels throughout and were less sensitive to decreases in gold data (*Figure 2, Supplementary Table 5*). When synthetic data were included in training, performance was maintained until approximately 50% of gold data were removed from the train set. Conversely, without synthetic data, performance dropped after about 10-20% of the gold data were removed from the train set mimicking a true low-resource setting.
Error analysis
The leading discrepancies between ground-truth and model prediction for each task are in *Supplementary Table 6*. Qualitative analysis revealed 4 distinct error patterns: Human annotator error; false positives and false negatives for Relationship and Support labels in the presence of any family mentions that did not correlate with the correct label; incorrect labels due to information present in the note but external to the sentence and therefore not accessible to the model or that required implied/assumed knowledge; and incorrectly labeling a non-adverse SDoH as an adverse SDoH.
ChatGPT-family model performance
When evaluating our fine-tuned Flan-T5 models on the synthetic test dataset against GPT-turbo-0613 and GPT4-0613, our model surpassed the performance of the top-performing 10-shot learning GPT model by a margin of Macro-F1 0.03 on any SDoH task (p\<0.01), but fall shorts on adverse SDoH task (p\<0.01) (*Table 5, Figure 3*).
Language model bias evaluation
Both fine-tuned Flan-T5 models and ChatGPT synthetic provided discrepant classification for sentence pairs with and without demographic information injected (*Figure 3*). However, the discrepancy rate of our fine-tuned models was nearly half that of ChatGPT: 14.3% vs. 21.5% of sentence pairs for any SDoH (P \= 0.007) and 9.9% vs. 18.2% of sentence pairs for adverse SDoH (P \= 0.005) for fine-tuned Flan-T5 vs. ChatGPT, respectively. ChatGPT was significantly more likely to change its classification when a female gender was injected compared to a male gender for the Any SDoH task (P \= 0.01); no other within-model comparisons were statistically significant. Sentences gold-labeled as Support for both any SDoH and adverse SDoH mentions were most likely to lead to discrepant predictions for ChatGPT (56.3% (27/48)) and (21.0% (9/29)), respectively). Employment gold-labeled sentences were most-likely to lead to discrepant prediction for any SDoH mention fine-tuned model (14.4% (13/90)), and Transportation for adverse SDoH mention fine-tuned model (12.2% (6/49)).
Comparison with structured EHR data
Our best-performing models for any SDoH mention correctly identified 95.7% (89/93) patients with at least one SDoH mention, and 93.8% (45/48) patients with at least one adverse SDoH mention (*Supplemental Tables 7-8*. SDoH entered as structured Z-code in the EHR during the same timespan identified 2.0% (1/48) with at least one adverse SDoH mention (all mapped Z-codes were adverse) (*Supplementary Table 9*). *Supplementary Figures 1-2* show that patient-level performance when using model predictions out-performed Z-codes by a factor of at least 3 for every label for each task (Macro-F1 0.78 vs. 0.17 for any SDoH mention and 0.71 vs. 0.17 for adverse SDoH mention).

## DISCUSSION

We developed multilabel classifiers to identify the presence of 6 different SDoH documented in clinical notes, demonstrating the potential of large LMs to improve the collection of real-world data on SDoH and support appropriate allocation of resource support to patients who need it most. We identified a performance gap between a more traditional BERT classifier and larger Flan-T5 XL and XXL models. Our fine-tuned models out-performed ChatGPT-family models with zero- and few-shot learning for most SDoH classes, and were less sensitive to the injection of demographic descriptors. Compared to diagnostic codes entered as structured data, text-extracted data identified 91.8% more patients with an adverse SDoH. We also contribute new annotation guidelines as well as synthetic SDoH datasets to the research community.

All of our models performed well at identifying sentences that do not contain SDoH mentions (F1 ≥ 0.99 for all). For any SDoH mentions, performance was worst for parental status and transportation issues. For adverse SDoH mentions, performance was worst for parental status and social support. These findings are unsurprising given the marked class imbalance for all SDoH labels—Only 3% of sentences in our training set contained any SDoH mention. Given this imbalance, our models’ ability to identify sentences that contain SDoH language is impressive. In addition, these SDoH descriptions are semantically and linguistically complex. In particular, sentences describing social support are highly variable given the variety of ways individuals can receive support from their social systems during care. Interestingly, our best-performing models demonstrated strong performance in classifying housing issues (macro-F1 0.67), which was our scarcest label with only 20 instances in the training dataset. This speaks to the potential of large LMs in improved real-world data collection for very sparsely documented information, which is the most likely to be missed via manual review.

The recent advancements in large LMs have opened a pathway for synthetic text generation that may improve model performance via data augmentation, and enable experiments that better protect patient privacy.[29](https://paperpile.com/c/yjfVx4/IXYR) This is an emerging area of research that falls within a larger body of work on synthetic patient data across a range of data types and end-uses.[30,31](https://paperpile.com/c/yjfVx4/2e9c+dSIb) Our study is among the first to evaluate the role of contemporary generative large LMs for synthetic clinical text to help unlock the value of unstructured data within the EHR. We were particularly interested in synthetic clinical data as a means to address the aforementioned scarcity of SDoH documentation, and our findings may provide generalizable insights for the common clinical NLP challenges of class imbalance—Many clinically important data are difficult to identify among the huge amounts of text in a patient’s EHR. We found variable benefits of synthetic data augmentation across model architecture and size; the strategy was most beneficial for the smaller Flan-T5 models and for the rarest classes where performance was dismal using gold data alone. Importantly, the ablation studies demonstrated that only approximately half of the gold-labeled dataset was needed to maintain performance when synthetic data was included in training, although synthetic data alone did not produce high-quality models. Of note, we aimed to understand whether synthetic data for augmentation could be automatically generated using ChatGPT-family models without additional human annotation, and so it is possible that manual gold-labeling could further enhance the value of these data. However, this would decrease the value of synthetic data in terms of reducing annotation effort.

Our novel approach to generating synthetic clinical sentences also enabled us to explore the potential for ChatGPT-family models, GPT3.5 and GPT4, for supporting the collection of SDoH information from the EHR. We found that fine-tuning LMs that are orders of magnitude smaller than ChatGPT-family models, even with our relatively small dataset, generally outperformed zero-shot and few-shot learning with ChatGPT-family models, consistent with prior work evaluating large LMs for clinical uses.[32–34](https://paperpile.com/c/yjfVx4/B8iK+mOrJ+sWuc)[32,33](https://paperpile.com/c/yjfVx4/B8iK+mOrJ) Nevertheless, these models showed promising performance given that they were not explicitly trained for clinical tasks, with the caveat that it is hard to make definite conclusions based on synthetic data. Additional prompt engineering could improve the performance of ChatGPT-family models, such as developing prompts that provide details of the annotation guidelines as done by Ramachandran et al (2023).[34](https://paperpile.com/c/yjfVx4/sWuc) This is an area for future study, especially once these models can be readily used with real clinical data. With additional prompt engineering and model refinement, performance of these models could improve in the future and provide a promising avenue to extract SDoH while reducing human effort needed to label training datasets.

It is well-documented that LMs learn the biases, prejudices, and racism present in the language they are trained on.[35–38](https://paperpile.com/c/yjfVx4/erUz+nFAs+OckR+kgzx) Thus, it is essential to evaluate how LMs could propagate existing biases, which in clinical settings could amplify the health disparities crisis.[1–3](https://paperpile.com/c/yjfVx4/j1dN+8yTi+Zp8L) We were especially concerned that SDoH-containing language may be especially prone to eliciting these biases. Both our fine-tuned models and ChatGPT altered their SDoH classification predictions when demographics and gender descriptors were injected into sentences, although the fine-tuned models were significantly more robust than ChatGPT. Although not significantly different, it is worth noting that for both the fine-tuned models and ChatGPT, Hispanic and Black descriptors were most likely to change the classification for any SDoH and adverse SDoH mentions, respectively. This lack of significance may be due to the small numbers in this evaluation, and future work is critically needed to further evaluate bias in clinical LMs. We have made our paired demographic-injected sentences openly available for future efforts on LM bias evaluation.

SDoH are notoriously under-documented in existing EHR structured data.[10–12,39](https://paperpile.com/c/yjfVx4/NfPNB+HNP8d+xuWCW+24iW) Our findings that text-extracted SDoH information was better able to identify patients with adverse SDoH than relevant billing codes are in agreement with prior work showing under-utilization of Z-codes[10,11](https://paperpile.com/c/yjfVx4/NfPNB+HNP8d). Most EMR systems have other ways to enter SDoH information as structured data which may have more complete documentation, however these did not exist for most of our target SDoH. Lyberger et al. evaluated other EHR sources of structured SDoH data, and similarly found that NLP methods are a complementary source SDoH information extraction, and were able to identify 10-30% of patients with tobacco, alcohol, and homelessness risk factors documented only in unstructured text[22](https://paperpile.com/c/yjfVx4/XEymp).

There have been several prior studies developing NLP methods to extract SDoH from the EHR.[13–21,40](https://paperpile.com/c/yjfVx4/dwSP+QKOo+3Z4R+tPmm+EfrS+v7vl+C5qx+ywEU+1P2G+cN0M) The most common SDoH targeted in prior efforts include smoking history, substance use, alcohol use, and homelessness.[23](https://paperpile.com/c/yjfVx4/M3kyq) In addition, many prior efforts focus only on text in the Social History section of notes. In a recent shared task on alcohol, drug, tobacco, employment, and living situation event extraction from Social History sections, pre-trained LMs similarly provided best performance.[41](https://paperpile.com/c/yjfVx4/fCVG) Using this dataset, one study found that sequence-to-sequence approaches out-performed classification approaches, in line with our findings.[42](https://paperpile.com/c/yjfVx4/CpfF) In addition to our technical innovations, our work adds to prior efforts by investigating SDoH that are less commonly targeted for extraction but nonetheless have been shown to impact healthcare.[43–51](https://paperpile.com/c/yjfVx4/uwVf+iwLA+YnfS+cq7p+eLSX+NszP+qacn+izwc+BTQg) We also developed methods that can mine information from full clinic notes, not only Social History sections—a fundamentally more challenging task with a much larger class imbalance. Clinically-impactful SDoH information is often scattered throughout other note sections and many note types, such as many inpatient progress notes and notes written by nurses and social workers, do not consistently contain Social History sections.

Our study has limitations. First, our training and out-of-domain datasets come from a predominantly white population treated at hospitals in Boston, Massachusetts in the United States of America. This limits the generalizability of our findings. We could not exhaustively assess the many methods to generate synthetic data from ChatGPT. Instead, we chose to investigate prompting methods that could be easily reproduced by others and did not require extensive task-specific optimization, as this is likely not feasible for the many clinical NLP tasks that one may wish to generate synthetic data on. Incorporating real clinical examples in the prompt would likely improve the quality of the synthetic data, and is an area of future research when large generative LMs become more widely available for use with protected health information and within the resource constraints of academic researchers and healthcare systems. Because we could not evaluate ChatGPT-family models using protected health information, our evaluations are limited to manually-verified synthetic sentences. Thus, our reported performance may not completely reflect true performance on real clinical text. Because the synthetic sentences were generated using ChatGPT itself, and ChatGPT presumably has not been trained on clinical text, we hypothesize that if anything, performance would be worse on real clinical data. Finally, our models can only be as good as the annotated corpus. SDoH annotation is challenging due to its conceptually complex nature, especially for the Support tag, and labeling may also be subject to annotator bias[52](https://paperpile.com/c/yjfVx4/vnxY), all of which may impact ultimate performance.

Our findings highlight the potential of large LMs to improve real-world data collection and identification of SDoH from the EHR. In addition, synthetic clinical text generated by large LMs may enable better identification of rare events documented in the EHR, although more work is needed to optimize generation methods. Our fine-tuned models were less prone to bias than ChatGPT-family models and out-performed for most SDoH classes, especially any SDoH mentions, despite being orders of magnitude smaller. In the future, these models could improve our understanding of drivers of health disparities by improving real-world evidence, and could directly support patient care by flagging patients who may benefit most from proactive resource and social work referral.

## METHODS

Data
Table 1 describes the patient populations of the datasets used in this study. Gender and race/ethnicity data and descriptors were collected from the EHR. These are generally collected either directly from the patient at registration, or by a provider, but the mode of collection for each data point was not available. Our primary dataset consisted of a corpus of 800 clinic notes from 770 patients with cancer who received radiotherapy (RT) at the Department of Radiation Oncology at Brigham and Women’s Hospital/Dana-Farber Cancer Institute in Boston, Massachusetts from 2015-2022. We also created two out-of-domain test datasets. First, we collected 200 clinic notes from 170 patients with cancer treated with immunotherapy at Dana-Farber Cancer, and not present in the RT dataset. Second, we collected 200 notes from 183 patients in the MIMIC (Medical Information Mart for Intensive Care)-III database[53,54](https://paperpile.com/c/yjfVx4/43rQc+l1GSM), which includes data associated with patients admitted to the critical care units at Beth Israel Deaconess Medical Center in Boston, Massachusetts from 2001-2008. This study was approved by the Mass General Brigham institutional review board, and consent was waived as this was deemed exempt human subjects research.

Only notes written by physicians, physician assistants, nurse practitioners, registered nurses, and social workers were included. To maintain a minimum threshold of information, we excluded notes with fewer than 150 tokens across all provider types. This helped ensure that the selected notes contained sufficient textual content. For notes written by all providers save social workers, we excluded notes containing any section longer than 500 tokens to avoid excessively lengthy sections that might have included less relevant or redundant information. For physician, physician assistant, and nurse practitioner notes, we used a customized medSpacy[55,56](https://paperpile.com/c/yjfVx4/nDjDz+W72ul) sectionizer to include only notes that contained at least one of the following sections: Assessment and Plan, Social History, and History/Subjective.

In addition, for the RT dataset, we established a date range, considering notes within a window of 30 days before the first treatment and 90 days after the last treatment. Additionally, in the fifth round of annotation, we specifically excluded notes from patients with zero social work notes. This decision ensured that we focused on individuals who had received social work intervention or had pertinent social context documented in their notes. For the immunotherapy dataset, we ensured that there was no patient overlap between RT and immunotherapy notes. We also specifically selected notes from patients with at least one social work note. To further refine the selection, we considered notes with a note date one month before or after the patient's first social work note or after it. For the MIMIC-III dataset, only notes written by physicians, social workers, and nurses were included for analysis. We focused on patients who had at least one social work note, without any specific date range criteria.

Prior to annotation, all notes were segmented into sentences using the syntok[57](https://paperpile.com/c/yjfVx4/Gjq4k) sentence segmenter as well as split on bullet points “•”. This method was used for all notes in the radiotherapy, immunotherapy, and MIMIC datasets for sentence-level annotation and subsequent classification.
Task definition and data labeling
We defined our label schema and classification tasks by first carrying out interviews with subject matter experts, including social workers, resource specialists, and oncologists, to determine SDoH that are clinically relevant but not already readily available as structured data in the EHR, especially as dynamic features over time. After initial interviews, a set of exploratory pilot annotations was conducted on a subset of clinical notes and preliminary annotation guidelines were developed. The guidelines were then iteratively refined and finalized based on the pilot annotations and additional input from subject matter experts. The following SDoH categories and their attributes were selected for inclusion in the project: Employment status (employed, unemployed, underemployed, retired, disability, student), Housing issue (financial status, undomiciled, other), Transportation issue (distance, resource, other), Parental status (if the patient has a child under 18 years old), Relationship (married, partnered, widowed, divorced, single), and Social support (presence or absence of social support).

We defined two multilabel sentence-level classification tasks:

1. Any SDoH mentions: The presence of language describing an SDoH category as defined above, regardless of the attribute.

2. Adverse SDoH mentions: The presence or absence of language describing an SDoH category with an attribute that could create an additional social work or resource support need for patients:

   * **Employment status**: *unemployed, underemployed, disability*

   * **Housing issue**: *financial status, undomiciled, other*

   * **Transportation issue**: *distance, resources, other*

   * **Parental status**: *having a child under 18 years old*

   * **Relationship**: *widowed, divorced, single*

   * **Social support**: *absence of social support*

After finalizing the annotation guidelines, two annotators manually annotated the RT corpus. In total, ten thousand one-hundred clinical notes were annotated line-by-line using the annotation software Multi-document Annotation Environment (MAE v2.2.13).[58](https://paperpile.com/c/yjfVx4/P9XW)  A total of 300/800 (37.5%) of the notes underwent dual annotation by two data scientists across 4 rounds. After each round, the data scientists and an oncologist performed discussion-based adjudication. Before adjudication, dually-annotated notes had a Krippendorf’s alpha agreement of 0.86 and Cohen’s Kappa of 0.86 for any SDoH mention categories. For adverse SDoH mentions, notes had a Krippendorf’s alpha agreement of 0.76 and Cohen’s Kappa of 0.76. Detailed agreement metrics are in *Supplementary Tables 1-2*. A single annotator then annotated the remaining radiotherapy notes, the immunotherapy dataset, and the MIMIC-III dataset. *Table 2* describes the distribution of labels across the datasets

The annotation/adjudication team was composed of one board-certified radiation oncologist who completed a postdoctoral fellowship in clinical natural language processing, a Master’s-level computational linguist with a Bachelor’s degree in linguistics and one year prior experience working specifically with clinical text, and a Master’s student in computational linguistics with a Bachelor’s degree in linguistics. The radiation oncologist and Master’s level computational linguist led the development of the annotation guidelines, and trained the Master’s student in SDoH annotation over a period of 1 month via review of the annotation guidelines and iterative review of pilot annotations. During adjudication, if there was still ambiguity, we discussed with the two Resource Specialists on the research team to provide input in adjudication.
Data augmentation
We employed synthetic data generation methods to assess the impact of data augmentation for the positive class, and also to enable an exploratory evaluation of proprietary large LMs that could not be downloaded locally thus cannot be used with protected health information. In round 1, GPT-turbo-0301(ChatGPT) version of GPT3.5 via the OpenAI[59](https://paperpile.com/c/yjfVx4/aC6KA) API was prompted to generate new sentences for each SDoH category, using sentences from the annotation guidelines as references. In round 2, in order to generate more linguistic diversity, the sample synthetic sentences output from round 1 were taken as references to again generate another set of synthetic sentences. One hundred sentences per category were generated in each round. *Supplementary Table 3* shows the prompts for each sentence label type.

Synthetic test set generation
Iteration 1 for generating SDoH sentences involved prompting the 538 synthetic sentences to be manually validated to evaluate ChatGPT, which cannot be used with protected health information. Of these, after human review only 480 were found to have any SDoH mention, and 289 to have an adverse SDoH mention (Table 2). For all synthetic data generation methods, no real patient data were used in prompt development or fine-tuning.
Model development
The radiotherapy corpus was split into a 60%/20%/20% distribution for training, development, and testing respectively. The entire immunotherapy and MIMIC-III corpora were held-out for out-of-domain test and were not used during model development.

The experimental phase of this study focused on investigating the effectiveness of different machine learning models and data settings for the classification of SDoH. We explored one multi-label BERT model as a baseline, namely bert-base-uncased[60](https://paperpile.com/c/yjfVx4/ABnp), as well as a range of Flan-T5 models[61,62](https://paperpile.com/c/yjfVx4/X5d6+eb93) including Flan-T5 base, large, XL, and XXL; where XL and XXL used a parameter efficient tuning method (low-rank adaptation (LoRA)[63](https://paperpile.com/c/yjfVx4/xoIw)). Binary cross-entropy loss with logits was used for BERT and cross-entropy loss for the Flan T5 models. Given the large class imbalance, non-SDoH sentences were undersampled during training. We assessed the impact of adding synthetic data on model performance. Details on model hyper-parameters are in *Supplementary Methods*.

For sequence-to-sequence models, input consisted of the input sentence with “summarize” appended in front, and the target label (when used during training) was the text span of the label from the target vocabulary. Because the output did not always exactly correspond to the target vocabulary, we post-processed the model output, which was a simple split function on “,” and dictionary mapping from observed miss-generation e.g., “RELAT → RELATIONSHIP”. Examples of this label resolution are in *Supplementary Methods.*
Ablation studies
Ablation studies were carried out to understand the impact of manually labeled training data quantity on performance when synthetic SDoH data is included in the training dataset. First, models were trained using 10%, 25%, 40%, 50%, 70%, 75%, and 90% of manually labeled sentences; both SDOH and non-SDOH sentences were reduced at the same rate. Evaluation was on the RT test set.
Evaluation
During training and fine-tuning, we evaluated all models using the RT development set and assessed their final performance using bootstrap sampling of the held-out RT test set. Bootstrap sample number and size was calculated to achieve a precision level for standard error of macro F1 of \+/- 0.01. The mean and 95% confidence intervals from the bootstrap samples were calculated from the resulting bootstrap samples. We also sampled to ensure that our standard error on the 95% confidence interval limits was \< 0.01 as follows: Our selected bootstrap sample size matched the test data size, sampling with replacement. We then computed the 5th and 95th percentile values for each of the calculated k samples from the resulting distributions. The standard deviation of these percentile values was subsequently determined to establish the precision of the confidence interval limits. Examples of the bootstrap sampling calculations are in *Supplementary Methods*.

For each classification task, we calculated precision/positive predictive value, recall/sensitivity, and F1 (harmonic mean of recall and precision) as follows:

* Precision \= TP/(TP+FP)

* Recall \= TP/(TP+FN)

* F1 \= (2\*Precision\*Recall)/(Precision+Recall)

* TP \= true positives, FP \= false positives, FN \= false negatives

Manual error analysis was conducted on the radiotherapy dataset using the best-performing model.
ChatGPT-family model evaluation
To evaluate ChatGPT, the Scikit-LLM[64](https://paperpile.com/c/yjfVx4/yYPKc) multi-label zero-shot classifier and few-shot binary classifier were adapted to form a multi-label zero- and few-shot classifier (*Figure 1*). A subset of 480 synthetic sentences whose labels were manually validated, were used for testing. Test sentences were inserted into the following prompt template, which instructs ChatGPT to act as a multi-label classifier model, and to label the sentences accordingly:

“Sample input: \[TEXT\]

Sample target: \[LABELS\]**”
\[TEXT\] was the exemplar from the development/exemplar set.
\[LABELS\] was a comma-separated list of the labels for that exemplar, e.g. PARENT,RELATIONSHIP.

Of note, because we were unable to generate high-quality synthetic non-SDoH sentences, these classifiers did not include a negative class. We evaluated the most current ChatGPT model freely available at the time of this work, GPT-turbo-0613, as well as GPT4-0613, via the OpenAI API with temperature 0 for reproducibility.
Language model bias evaluation
In order to test for bias in our best-performing models and in large LMs pre-trained on general text, we used GPT4 to insert demographic descriptors into our synthetic data, as illustrated in *Figure 2*. GPT4 was supplied with our synthetically-generated test sentences, and prompted to insert demographic information into them. For example, a sentence starting with "Widower admits fears surrounding potential judgment…" might become “Hispanic widower admits fears surrounding potential judgment…".  The prompt was as follows (in a batch of 10 ensure demographic variations):

"role": "user", "content": **“**\[ORIGINAL SENTENCE\]\\n swap the sentences patients above to one of the race/ethnicity \[Asian, Black, white, Hispanic\] and gender, and put the modified race and gender in bracket at the beginning like this \\n Owner operator food truck selling gourmet grilled cheese sandwiches around town \=\> \\n \[Asian female\] Asian woman owner operator of a food truck selling gourmet grilled cheese sandwiches around town”

\[ORIGINAL SENTENCE\]was a sentence from a selected subset of our GPT-3.5-generated synthetic data

These sentences were then manually validated; 419 had any SDoH mention, and 253 had an adverse SDoH mention.

**Comparison with structured EHR data**

To assess the completeness of SDoH documentation in structured versus unstructured EHR data, we collected Z-codes for all patients in our test set. Z-codes are SDoH-related ICD-10-CM diagnostic codes, mapped most closely with our SDoH categories present as structured data for the radiotherapy dataset (*Supplementary Table 4*). Text-extracted patient-level SDoH information was defined as the presence of one or more labels in any note. We compared these patient-level labels to structured Z-codes entered in the EHR during the same time frame.
Statistical analysis
Macro-F1 performance for each model type was compared when developed with or without synthetic data and for the ChatGPT-family model comparisons using the Mann-Whitney U-test. The rate of discrepant SDoH classifications with and without the injection of demographic information were compared between the best-performing fine-tuned models and ChatGPT using chi-squared tests for multi-class comparisons and 2-proportion z-tests for binary comparisons. A 2-sided P ≤ 0.05 was considered statistically significant. Statistical analyses were carried out using the statistical Python package in scipy (Scipy.org). Python version 3.9.16 (Python Software Foundation) was used to carry out this work.
Data availability statement:** The RT and immunotherapy datasets cannot be shared for the privacy of the individuals whose data were used in this study.  All synthetic datasets used in this study are available at: https://github.com/AIM-Harvard/SDoH. The annotated MIMIC-III dataset is available after completion of a data use agreement at https://physionet.org/content/annotation-dataset-sdoh/1.0.1/.

Code availability statement:** The final annotation guidelines and all synthetic datasets used in this study are available at: [https://github.com/AIM-Harvard/SDoH](https://github.com/AIM-Harvard/SDoH).

Table 1\. Patient demographics across datasets

| Patients | Radiotherapy (in-domain) Dataset |  |  |  | Out-of-Domain Validation |  |  |  |
| :---- | ----- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |

|  | Total (n=770) | Train Set (n= 462\) | Development Set (n= 154\) | Test Set (n= 154\) | Immunotherapy (n=170) | MIMIC-III (n=183) | Synthetic Validated (n=480) | Synthetic Demo (n=419) |
| **Gender** |  |  |  |  |  |  |  |  |

| Male | 344  (44.7%) | 210 (45.5%) | 70  (45.5%) | 64 (41.6%) | 75 (44.1%) | 101  (55.2%) | N/A | 168 (40.1%) |
| Female | 426  (55.3%) | 252 (54.5%) | 84  (54.5%) | 90 (58.4%) | 95 (55.9%) | 82  (44.8%) | N/A | 177 (42.2%) |
| Not specified | 0 | 0 | 0 | 0 | 0 | 0 | N/A | 74 (17.7%) |
| **Race** |  |  |  |  |  |  |  |  |

| White | 664  (86.2%) | 396 (85.7%) | 134  (87.0%) | 134 (87.0%) | 137 (80.6%) | 132  (72.1%) | N/A | 113  (26.9%) |
| Asian | 21  (2.7%) | 11  (2.4%) | 6  (3.9%) | 4  (2.6%) | 9 (5.3%) | 5  (2.7%) | N/A | 106 (21.6%) |
| Black | 37  (4.8%) | 24  (5.2%) | 5  (3.2%) | 8  (5.2%) | 11 (6.5%) | 16  (8.7%) | N/A | 84  (25.7%) |
| Two or more | 3  (0.4%) | 2  (0.4%) | 0 | 1  (0.6%) | 0 | 3  (1.6%) | N/A | 0 |
| Others | 25  (3.2%) | 17  (3.7%) | 5  (3.2%) | 3  (1.9%) | 10 (5.9%) | 1  (0.6%) | N/A | 97  (23.2%) |
| Unknown | 20  (2.6%) | 12  (2.6%) | 4  (2.6%) | 4 (2.6%) | 3 (1.8%) | 25  (13.7%) | N/A | 19  (4.5%) |
| **Ethnicity** |  |  |  |  |  |  |  |  |

| Non- Hispanic | 682  (88.6%) | 420 (90.9%) | 130  (84.4%) | 132 (85.7%) | 160 (94.1%) | 158  (86.3%) | N/A | 322 (76.8%) |

| Hispanic | 11  (1.4%) | 8  (1.7%) | 2  (1.3%) | 1  (0.6%) | 20 (5.9%) | 11  (6.0%) | N/A | 97  (23.2%) |
| Unknown | 77  (10.0%) | 34  (7.4%) | 22  (14.3%) | 21 (13.6%) | 0 | 14  (7.7%) | N/A | 0 |

All data presented as n (%) unless otherwise noted. Synthetic Validated are the sentences used to evaluate GPT models, thus there is no demographic information for this dataset. Synthetic Demo are the sentences used for bias evaluation, where demographic descriptors were inserted. N/A \= not applicable.
Table 2\. Distribution of documents and sentence labels in each dataset

| Number of Documents |  |  |  |  |  |  |  |
| ----- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |

|  | Radiotherapy |  |  | Immunotherapy | MIMIC-III | Synthetic Validated | Synthetic Demo |
|  | Train Set | Development Set | Test Set |  |  |  |  |
| Documents | 481 | 160 | 159 | 200 | 200 | N/A | N/A |
| Number of Sentences \- Any SDoH Mentions |  |  |  |  |  |  |  |

|  | Radiotherapy |  |  | Immunotherapy (n=14,761) | MIMIC-III (n=5,328) | Synthetic Validated (n=480) | Synthetic Demo (n=419) |
| Label | Train Set (n=29,869) | Development Set (n=10,712) | Test Set (n=10,860) |  |  |  |  |
| No SDoH | 28992 (97.1%) | 10429 (97.4%) | 10582 (97.4%) | 14319  (97.0%) | 4968 (93.2%) | N/A | N/A |
| Employment | 218 (0.7%) | 65 (0.6%) | 64 (0.6%) | 103 (0.7%) | 70 (1.3%) | 136 (28.3%) | 132 (31.5%) |
| Housing | 20 (0.1%) | 7 (0.1%) | 4 (0.0%) | 13 (0.1%) | 3 (0.1%) | 69 (14.4%) | 64 (15.3%) |
| Parent | 53 (0.2%) | 24 (0.2%) | 22 (0.2%) | 30 (0.2%) | 27 (0.5%) | 67 (14.0%) | 43 (10.3%) |
| Relationship | 464 (1.6%) | 153 (1.4%) | 158 (1.5%) | 241 (1.6%) | 180 (3.4%) | 152 (31.7%) | 134 (32.0%) |
| Social Support | 234 (0.8%) | 51 (0.5%) | 61 (0.6%) | 86 (0.6%) | 122 (2.3%) | 102 (21.3%) | 90 (21.5%) |
| Transportation | 41 (0.1%) | 13 (0.1%) | 6 (0.1%) | 25 (0.2%) | 3 (0.1%) | 61 (12.7%) | 58 (13.8%) |
| Number of Sentences \- Adverse SDoH Mentions |  |  |  |  |  |  |  |

|  | Radiotherapy |  |  | Immunotherapy (n=14,761) | MIMIC-III (n=5,328) | Synthetic Validated (n=289) | Synthetic Demo (n=253) |
| Label | Train Set (n=29,869) | Development Set (n=10,712) | Test Set (n=10,860) |  |  |  |  |
| No Adverse SDoH | 29550 (98.9%) | 10615  (99.1%) | 10761 (99.1%) | 14621  (99.1%) | 5213 (97.8%) | N/A | N/A |
| Employment | 93 (0.3%) | 23 (0.2%) | 30 (0.3%) | 37 (0.3%) | 39 (0.7%) | 40 (13.8%) | 39 (15.4%) |
| Housing | 20 (0.1%) | 7 (0.1%) | 4 (0.0%) | 13 (0.1%) | 3 (0.1%) | 69 (23.9%) | 64 (25.3%) |
| Parent | 53 (0.2%) | 24 (0.2%) | 22 (0.2%) | 30 (0.2%) | 27 (0.5%) | 67 (23.2%) | 43 (17.0%) |
| Relationship | 86 (0.3%) | 27 (0.3%) | 31 (0.3%) | 30 (0.2%) | 23 (0.4%) | 68 (23.5%) | 62 (24.5%) |
| Social Support | 54 (0.2%) | 8 (0.1%) | 12 (0.1%) | 12 (0.1%) | 27 (0.5%) | 39 (13.5%) | 43 (17.0%) |
| Transportation | 41 (0.1%) | 13 (0.1%) | 6 (0.1%) | 25 (0.2%) | 3 (0.1%) | 61 (21.1%) | 58 (22.9%) |

All data presented as n (%) unless otherwise noted. Synthetic Validated are the sentences used to evaluate GPT models, thus there is no demographic information for this dataset. Synthetic Demo are the sentences used for bias evaluation, where demographic descriptors were inserted. Labels sum to \> 100% because some sentences had more than 1 SDoH label. SDoH \= social determinants of health; N/A \= not applicable
Table 3\. Model performance on the in-domain RT test dataset

| Any Social Determinant of Health (SDoH) |  |  |  |  |  |  |  |  |  |  |  |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |

| Model | Parameters (Total/Tuned) | Macro-F1 |  |  | No SDoH | Employment | Housing | Parent | Relationship | Social Support | Transportation |
|  |  | Mean  (95% CI)a | Delta F1b | P-value |  |  |  |  |  |  |  |
| **BERT-base** | 110M/110M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.53 (0.46-0.59) | \-0.06 | \<0.01 | 1.00 | 0.72 | 0.00 | 0.00 | **0.96** | 0.59 | 0.50 |

| Gold \+ synthetic data |  | 0.47 (0.44-0.52) |  |  | 1.00 | 0.62 | 0.00 | 0.29 | 0.93 | 0.49 | 0.00 |

| **Flan-T5-base** | 250M/250M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.36 (0.34-0.39) | \+0.13 | \<0.01 | 0.99 | 0.34 | 0.00 | 0.00 | 0.83 | 0.38 | 0.00 |
| Gold \+ synthetic data |  | 0.49 (0.40-0.60) |  |  | 1.00 | 0.67 | 0.37 | 0.00 | 0.93 | 0.28 | 0.25 |

| **Flan-T5-large** | 780M/780M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.42 (0.40-0.45) | \+0.18 | \<0.01 | 1.00 | 0.72 | 0.00 | 0.00 | 0.93 | 0.31 | 0.00 |
| Gold \+ synthetic data |  | 0.60 (0.50-0.68) |  |  | 1.00 | 0.76 | 0.67 | 0.24 | 0.91 | 0.48 | 0.18 |

| **Flan-T5 XL** | 3B/9.5M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.65  (0.54-0.73) | \+0.03 | \<0.01 | 0.99 | 0.71 | 0.57 | 0.55 | 0.92 | 0.50 | 0.31 |
| Gold \+ synthetic data |  | 0.68  (0.59-0.76) |  |  | 1.00 | 0.73 | 0.55 | 0.56 | 0.94 | 0.52 | **0.53** |

| **Flan-T5 XXL** | 11B/18M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.65  (0.56-0.75) | \+0.05 | \<0.01 | 1.00 | 0.76 | 0.33 | **0.65** | 0.95 | 0.51 | 0.44 |

| Gold \+ synthetic data |  | **0.70  (0.60-0.77)** |  |  | 1.00 | **0.80** | **0.67** | 0.47 | 0.93 | **0.60** | 0.47 |

|  Adverse Social Determinants of Health (SDoH) |  |  |  |  |  |  |  |  |  |  |  |
| Model | Parameters (Total/Tuned) | Macro-F1 |  |  | No SDoH | Employment | Housing | Parent | Relationship | Social Support | Transportation |
|  |  | Mean  (95% CI) | Delta F1 | P-value |  |  |  |  |  |  |  |
| **BERT-base** | 110M/110M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.64 (0.55-0.73) | \-0.09 | \<0.01 | 1.00 | 0.68 | 0.67 | 0.31 | 0.90 | 0.37 | **0.60** |

| Gold \+ synthetic data |  | 0.55 (0.45-0.67) |  |  | 1.00 | **0.75** | 0.37 | 0.36 | 0.78 | 0.38 | 0.4  |

| **Flan-T5-base** | 250M/250M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.24  (0.18 \- 0.31) | \+0.11 | \<0.01 | 1.00 | 0.00 | 0.00 | 0.00 | 0.43 | 0.00 | 0.25 |

| Gold \+ synthetic data |  | 0.35 (0.26 \- 0.45) |  |  | 1.00 | 0.30 | 0.33 | 0.00 | 0.56 | 0.00 | 0.25 |

| **Flan-T5-large** | 780M/780M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.27  (0.23-0.31) | \+0.22 | \<0.01 | 0.99 | 0.46 | 0.00 | 0.00 | 0.47 | 0.00 | 0.00 |
| Gold \+ synthetic data |  | 0.49 (0.40-0.59) |  |  | 1.00 | 0.58 | 0.54 | 0.33 | 0.66 | 0.22 | 0.17 |

| **Flan-T5 XL** | 3B/9.5M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | **0.69 (0.57-0.78)** | 0.00 | 0.53 | 1.00 | 0.76 | 0.57 | 0.52 | **0.93** | 0.44 | 0.67 |

| Gold \+ synthetic data |  | **0.69 (0.57-0.77)** |  |  | 1.00 | 0.72 | **0.67** | 0.49 | 0.87 | **0.56** | 0.57 |

| **Flan-T5 XXL** | 11B/18M |  |  |  |  |  |  |  |  |  |  |

| Gold data only |  | 0.63 (0.52-0.72) | \+0.03 | \<0.01 | 1.00 | 0.67 | 0.50 | **0.60** | 0.91 | 0.31 | 0.45 |

| Gold \+ synthetic data |  | 0.66 (0.55-0.74) |  |  | 1.00 | 0.62 | 0.60 | 0.55 | 0.89 | 0.53 | 0.46 |

The 95% CI for macro F1 is calculated by bootstrapping 3400 times (to achieve bootstrap SE \< 0.01) with replacement. The SE of the 95% confidence interval limits is 0.0091, ascertained by performing bootstrapping 3,400 times on three distinct samples. Delta F1 score is the change in Macro-F1 when synthetic data is added to the fine-tuning data. Bolded text indicates the best performance with and without synthetic data augmentation. p-values are computed with Mann-Whitney U-test. CI \= confidence interval; SE \= standard error.
Table 4\. Results of the best-performing models on the out-of-domain test datasets

| Any Social Determinant of Health (SDoH) |  |  |  |  |  |  |  |  |  |  |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |

| Dataset | Macro-F1 |  |  | No SDoH | Employment | Housing | Parent | Relationship | Social Support | Transportation |
| **Immunotherapy** | Mean  (95% CI) | Delta F1 | P-value |  |  |  |  |  |  |  |

| FlanXXL: Gold data only | 0.70 (0.63-0.76) | \+0.01 | \<0.01 | 0.99 | 0.83 | 0.55 | 0.69 | 0.93 | 0.46 | 0.46 |
| FlanXXL: Gold \+ synthetic data | 0.71 (0.64-0.76) |  |  | 0.99 | 0.79 | 0.55 | 0.68 | 0.91 | 0.63 | 0.40 |

| **MIMIC-III** |  |  |  |  |  |  |  |  |  |  |

| FlanXXL: Gold data only | 0.57 (0.49-0.63) | \-0.02 | \<0.01 | 0.98 | 0.65 | 0.00 | 0.63 | 0.91 | 0.32 | 0.50 |
| FlanXXL: Gold \+ synthetic data | 0.55 (0.49-0.61) |  |  | 0.98 | 0.69 | 0.24 | 0.44 | 0.91 | 0.33 | 0.24 |

| Adverse Social Determinants of Health (SDoH) |  |  |  |  |  |  |  |  |  |  |
| Dataset | Macro-F1 |  |  | No SDoH | Employment | Housing | Parent | Relationship | Social Support | Transportation |
| **Immunotherapy** | Mean  (95% CI)a | Delta F1b | P-value |  |  |  |  |  |  |  |

| FlanXL: Gold data only |  0.63 (0.54-0.72) | \+0.03 | \<0.01 | 1.00 | 0.56 | 0.46 | 0.68 | 0.81 | 0.50 | 0.46 |
| FlanXL: Gold \+ synthetic data | 0.66 (0.58-0.72) |  |  | 1.00 | 0.60 | 0.63 | 0.60 | 0.81 | 0.59 | 0.40 |

| **MIMIC-III** |  |  |  |  |  |  |  |  |  |  |

| FLANXL: Gold data only | 0.53 (0.47-0.60) | \-0.02 | \<0.01 | 0.99 | 0.51 | 0.50 | 0.53 | 0.65 | 0.22 | 0.20 |
| FLANXL: Gold \+ synthetic data | 0.51 (0.43-0.59) |  |  | 0.99 | 0.55 | 0.35 | 0.54 | 0.68 | 0.43 | 0.20 |

The 95% CI for macro F1 is calculated by bootstrapping 3400 times (to achieve bootstrap SE \< 0.01) with replacement. The SE of the 95% confidence interval limits is 0.0074, ascertained by performing bootstrapping 3,400 times on three distinct samples. Delta F1 score is the change in Macro-F1 when synthetic data is added to the fine-tuning data. Bolded text indicates the best performance with and without synthetic data augmentation. p-values are computed with Mann-Whitney U-test. CI \= confidence interval; SE \= standard error.
Table 5\. Model performance on synthetic test data

| Any Social Determinant of Health (SDoH) |  |  |  |  |  |  |  |  |
| ----- | :---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |

|  Model Parameters |  | Mean macro F1 (95% CI) | Employment | Housing | Parent | Relationship | Social Support | Transportation |
| **FT Flan-T5 XXL** | 11B | **0.92 (0.62-0.95)** | **0.92** | **0.91** | 0.63 | **0.95** | **0.77** | **0.93** |

| **GPT-3.5** | 175B |  |  |  |  |  |  |  |

| Zero-shot |  | 0.84 (0.48-0.95) | 0.94 | 0.87 | 0.85 | 0.82 | 0.49 | 0.84 |
| 10-shot |  | 0.82 (0.60-0.90) | 0.89 | 0.89 | 0.76 | 0.79 | 0.61 | 0.85 |
| **GPT-4** | Unknown |  |  |  |  |  |  |  |

| Zero-shot |  | 0.85 (0.48-0.94) | 0.94 | 0.83 | 0.72 | 0.88 | 0.49 | 0.86 |
| 10-shot |  | 0.88 (0.58-0.93) | 0.91 | 0.90 | **0.96** | 0.82 | 0.59 | 0.91 |

| Adverse Social Determinants of Health (SDoH) |  |  |  |  |  |  |  |  |
|  Model Parameters |  | Mean macro F1 (95% CI)a | Employment | Housing | Parent | Relationship | Social Support | Transportation |
| **FT Flan-T5 XL** | 3B | 0.86 (0.65-0.98) | 0.86 | 0.86 | 0.65 | **0.98** | **0.84** | 0.86 |

| **GPT-3.5** | 175B |  |  |  |  |  |  |  |

| Zero-shot |  | 0.82 (0.51-0.95) | 0.77 | 0.93 | 0.87 | 0.72 | 0.52 | 0.94 |
| 10-shot |  | 0.81 (0.50-0.94) | **0.93** | 0.83 | 0.78 | 0.70 | 0.50 | 0.93 |

| **GPT-4** | Unknown |  |  |  |  |  |  |  |

| Zero-shot |  | 0.84 (0.52-0.94) | 0.79 | **0.94** | **0.94** | 0.78 | 0.53 | 0.89 |

| 10-shot |  | **0.90 (0.71-0.96)** | 0.92 | 0.91 | 0.90 | 0.73 | 0.73 | **0.96** |

The 95% CI (Confidence interval) for macro F1 is calculated by bootstrapping 10000 times (to achieve bootstrap SE \< 0.01) with replacement. The SE of the 95% confidence interval limits is 0.0038, ascertained by performing bootstrapping 10,000 times on three distinct samples. Bolded text indicates the best performance. FT \= fine-tuned. CI \= confidence interval. SE \= standard error.

## REFERENCES

1\.	[Lavizzo-Mourey, R. J., Besser, R. E. & Williams, D. R. Understanding and Mitigating Health Inequities \- Past, Current, and Future Directions. *N. Engl. J. Med.* **384**, 1681–1684 (2021).](http://paperpile.com/b/yjfVx4/j1dN)

2\.	[Chetty, R. *et al.* The Association Between Income and Life Expectancy in the United States, 2001-2014. *JAMA* **315**, 1750–1766 (2016).](http://paperpile.com/b/yjfVx4/8yTi)

3\.	[Caraballo, C. *et al.* Excess Mortality and Years of Potential Life Lost Among the Black Population in the US, 1999-2020. *JAMA* **329**, 1662–1670 (2023).](http://paperpile.com/b/yjfVx4/Zp8L)

4\.	[Social determinants of health.](http://paperpile.com/b/yjfVx4/9pBzf) [http://www.who.int/social\_determinants/sdh\_definition/en/](http://www.who.int/social_determinants/sdh_definition/en/)[.](http://paperpile.com/b/yjfVx4/9pBzf)
5\.	[Franke, H. A. Toxic Stress: Effects, Prevention and Treatment. *Children* **1**, 390–402 (2014).](http://paperpile.com/b/yjfVx4/HoSYw)

6\.	[Nelson, C. A. *et al.* Adversity in childhood is linked to mental and physical health throughout life. *BMJ* **371**, m3048 (2020).](http://paperpile.com/b/yjfVx4/VXeKa)

7\.	[Shonkoff, J. P., Garner, A. S., Committee on Psychosocial Aspects of Child and Family Health, Committee on Early Childhood, Adoption, and Dependent Care & Section on Developmental and Behavioral Pediatrics. The lifelong effects of early childhood adversity and toxic stress. *Pediatrics* **129**, e232–46 (2012).](http://paperpile.com/b/yjfVx4/dQla1)

8\.	[Turner-Cobb, J. M., Sephton, S. E., Koopman, C., Blake-Mortimer, J. & Spiegel, D. Social support and salivary cortisol in women with metastatic breast cancer. *Psychosom. Med.* **62**, 337–345 (2000).](http://paperpile.com/b/yjfVx4/zvwv7)

9\.	[Hood, C. M., Gennuso, K. P., Swain, G. R. & Catlin, B. B. County Health Rankings: Relationships Between Determinant Factors and Health Outcomes. *Am. J. Prev. Med.* **50**, 129–135 (2016).](http://paperpile.com/b/yjfVx4/QlpcC)

10\.	[Truong, H. P. *et al.* Utilization of Social Determinants of Health ICD-10 Z-Codes Among Hospitalized Patients in the United States, 2016-2017. *Med. Care* **58**, 1037–1043 (2020).](http://paperpile.com/b/yjfVx4/NfPNB)

11\.	[Heidari, E., Zalmai, R., Richards, K., Sakthisivabalan, L. & Brown, C. Z-code documentation to identify social determinants of health among Medicaid beneficiaries. *Res. Social Adm. Pharm.* **19**, 180–183 (2023).](http://paperpile.com/b/yjfVx4/HNP8d)

12\.	[Wang, M., Pantell, M. S., Gottlieb, L. M. & Adler-Milstein, J. Documentation and review of social determinants of health data in the EHR: measures and associated insights. *J. Am. Med. Inform. Assoc.* **28**, 2608–2616 (2021).](http://paperpile.com/b/yjfVx4/xuWCW)

13\.	[Conway, M. *et al.* Moonstone: a novel natural language processing system for inferring social risk from clinical narratives. *J. Biomed. Semantics* **10**, 1–10 (2019).](http://paperpile.com/b/yjfVx4/dwSP)

14\.	[Bejan, C. A. *et al.* Mining 100 million notes to find homelessness and adverse childhood experiences: 2 case studies of rare and severe social determinants of health in electronic health records. *J. Am. Med. Inform. Assoc.* **25**, 61–71 (2017).](http://paperpile.com/b/yjfVx4/QKOo)

15\.	[Topaz, M., Murga, L., Bar-Bachar, O., Cato, K. & Collins, S. Extracting Alcohol and Substance Abuse Status from Clinical Notes: The Added Value of Nursing Data. *Stud. Health Technol. Inform.* **264**, 1056–1060 (2019).](http://paperpile.com/b/yjfVx4/3Z4R)

16\.	[Gundlapalli, A. V. *et al.* Using natural language processing on the free text of clinical documents to screen for evidence of homelessness among US veterans. *AMIA Annu. Symp. Proc.* **2013**, 537–546 (2013).](http://paperpile.com/b/yjfVx4/tPmm)

17\.	[Hammond, K. W., Ben-Ari, A. Y., Laundry, R. J., Boyko, E. J. & Samore, M. H. The Feasibility of Using Large-Scale Text Mining to Detect Adverse Childhood Experiences in a VA-Treated Population. *J. Trauma. Stress* **28**, 505–514 (2015).](http://paperpile.com/b/yjfVx4/EfrS)

18\.	[Han, S. *et al.* Classifying social determinants of health from unstructured electronic health records using deep learning-based natural language processing. *J. Biomed. Inform.* **127**, 103984 (2022).](http://paperpile.com/b/yjfVx4/v7vl)

19\.	[Rouillard, C. J., Nasser, M. A., Hu, H. & Roblin, D. W. Evaluation of a Natural Language Processing Approach to Identify Social Determinants of Health in Electronic Health Records in a Diverse Community Cohort. *Med. Care* **60**, 248–255 (2022).](http://paperpile.com/b/yjfVx4/C5qx)

20\.	[Feller, D. J. *et al.* Detecting Social and Behavioral Determinants of Health with Structured and Free-Text Clinical Data. *Appl. Clin. Inform.* **11**, 172–181 (2020).](http://paperpile.com/b/yjfVx4/ywEU)

21\.	[Yu, Z. *et al.* A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models. *AMIA Annu. Symp. Proc.* **2021**, 1225–1233 (2021).](http://paperpile.com/b/yjfVx4/1P2G)

22\.	[Lybarger, K. *et al.* Leveraging natural language processing to augment structured social determinants of health data in the electronic health record. *J. Am. Med. Inform. Assoc.* (2023) doi:](http://paperpile.com/b/yjfVx4/XEymp)[10.1093/jamia/ocad073](http://dx.doi.org/10.1093/jamia/ocad073)[.](http://paperpile.com/b/yjfVx4/XEymp)

23\.	[Patra, B. G. *et al.* Extracting social determinants of health from electronic health records using natural language processing: a systematic review. *J. Am. Med. Inform. Assoc.* **28**, 2716–2727 (2021).](http://paperpile.com/b/yjfVx4/M3kyq)

24\.	[Xu, D., Chen, S. & Miller, T. BCH-NLP at BioCreative VII Track 3: medications detection in tweets using transformer networks and multi-task learning. Preprint at](http://paperpile.com/b/yjfVx4/OqrO) https://arxiv.org/abs/2111.13726 [(2021).](http://paperpile.com/b/yjfVx4/OqrO)
25\.	[Chen, S. *et al.* Natural Language Processing to Automatically Extract the Presence and Severity of Esophagitis in Notes of Patients Undergoing Radiotherapy. *JCO Clin Cancer Inform* **7**, e2300048 (2023).](http://paperpile.com/b/yjfVx4/59gr)

26\.	Tan, R.S.Y.C. *et al.* Inferring cancer disease response fromradiology reports using large language models with data augmentation and prompting. *J Am Med Inform Assoc* **30**(10):1657-1664 (2023).

27\.	[Jung, J. *et al.* Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing. Preprint at](http://paperpile.com/b/yjfVx4/PbaK) https://arxiv.org/pdf/2305.16635.pdf (2023).

28\.	[Lett, E. & La Cava, W. G. Translating intersectionality to fair machine learning in health sciences. *Nature Machine Intelligence* **5**, 476–479 (2023).](http://paperpile.com/b/yjfVx4/RBOwB)

29\.	[Li, J. *et al.* Are synthetic clinical notes useful for real natural language processing tasks: A case study on clinical entity recognition. *J. Am. Med. Inform. Assoc.* **28**, 2193–2201 (2021).](http://paperpile.com/b/yjfVx4/IXYR)

30\.	[Chen, R. J., Lu, M. Y., Chen, T. Y., Williamson, D. F. K. & Mahmood, F. Synthetic data in machine learning for medicine and healthcare. *Nat Biomed Eng* **5**, 493–497 (2021).](http://paperpile.com/b/yjfVx4/2e9c)

31\.	[Jacobs, F. *et al.* Opportunities and Challenges of Synthetic Data Generation in Oncology. *JCO Clin Cancer Inform* **7**, e2300045 (2023).](http://paperpile.com/b/yjfVx4/dSIb)

32\.	[Chen, S. *et al.* Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification. Preprint at](http://paperpile.com/b/yjfVx4/B8iK) https://arxiv.org/abs/2304.02496 [(2023).](http://paperpile.com/b/yjfVx4/B8iK)

33\.	[Lehman, E. *et al.* Do We Still Need Clinical Language Models? *arXiv \[cs.CL\]* (2023).](http://paperpile.com/b/yjfVx4/mOrJ)

34\.	[Ramachandran, G. K. *et al.* Prompt-based Extraction of Social Determinants of Health Using Few-shot Learning. in *Proceedings of the 5th Clinical Natural Language Processing Workshop* 385–393 (Association for Computational Linguistics, 2023).](http://paperpile.com/b/yjfVx4/sWuc)

35\.	[Feng, S., Park, C. Y., Liu, Y. & Tsvetkov, Y. From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models. in *Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)* 11737–11762 (Association for Computational Linguistics, 2023).](http://paperpile.com/b/yjfVx4/erUz)

36\.	[Zhao, J., Wang, T., Yatskar, M., Ordonez, V. & Chang, K.-W. Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints. in *Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing* 2979–2989 (Association for Computational Linguistics, 2017).](http://paperpile.com/b/yjfVx4/nFAs)

37\.	[Caliskan, A., Bryson, J. J. & Narayanan, A. Semantics derived automatically from language corpora contain human-like biases. *Science* **356**, 183–186 (2017).](http://paperpile.com/b/yjfVx4/OckR)

38\.	[Davidson, T., Warmsley, D., Macy, M. & Weber, I. Automated Hate Speech Detection and the Problem of Offensive Language. Preprint at https://arxiv.org/pdf/1703.04009.pdf (2017).](http://paperpile.com/b/yjfVx4/kgzx)
39\.	[Kharrazi, H. *et al.* The Value of Unstructured Electronic Health Record Data in Geriatric Syndrome Case Identification. *J. Am. Geriatr. Soc.* **66**, 1499–1507 (2018).](http://paperpile.com/b/yjfVx4/24iW)

40\.	[Derton, A. *et al.* Natural Language Processing Methods to Empirically Explore Social Contexts and Needs in Cancer Patient Notes. *JCO Clin Cancer Inform* **7**, e2200196 (2023).](http://paperpile.com/b/yjfVx4/cN0M)

41\.	[Lybarger, K., Yetisgen, M. & Uzuner, Ö. The 2022 n2c2/UW shared task on extracting social determinants of health. *J. Am. Med. Inform. Assoc.* **30**, 1367–1378 (2023).](http://paperpile.com/b/yjfVx4/fCVG)

42\.	[Romanowski, B., Ben Abacha, A. & Fan, Y. Extracting social determinants of health from clinical note text with classification and sequence-to-sequence approaches. *J. Am. Med. Inform. Assoc.* **30**, 1448–1455 (2023).](http://paperpile.com/b/yjfVx4/CpfF)

43\.	[Hatef, E. *et al.* Assessing the Availability of Data on Social and Behavioral Determinants in Structured and Unstructured Electronic Health Records: A Retrospective Analysis of a Multilevel Health Care System. *JMIR Med Inform* **7**, e13802 (2019).](http://paperpile.com/b/yjfVx4/uwVf)

44\.	[Greenwald, J. L., Cronin, P. R., Carballo, V., Danaei, G. & Choy, G. A Novel Model for Predicting Rehospitalization Risk Incorporating Physical Function, Cognitive Status, and Psychosocial Support Using Natural Language Processing. *Med. Care* **55**, 261–266 (2017).](http://paperpile.com/b/yjfVx4/iwLA)

45\.	[Blosnich, J. R. *et al.* Social Determinants and Military Veterans’ Suicide Ideation and Attempt: a Cross-sectional Analysis of Electronic Health Record Data. *J. Gen. Intern. Med.* **35**, 1759–1767 (2020).](http://paperpile.com/b/yjfVx4/YnfS)

46\.	[Wray, C. M. *et al.* Examining the Interfacility Variation of Social Determinants of Health in the Veterans Health Administration. *Fed. Pract.* **38**, 15–19 (2021).](http://paperpile.com/b/yjfVx4/cq7p)

47\.	[Wang, L. *et al.* Disease Trajectories and End-of-Life Care for Dementias: Latent Topic Modeling and Trend Analysis Using Clinical Notes. *AMIA Annu. Symp. Proc.* **2018**, 1056–1065 (2018).](http://paperpile.com/b/yjfVx4/eLSX)

48\.	[Navathe, A. S. *et al.* Hospital Readmission and Social Risk Factors Identified from Physician Notes. *Health Serv. Res.* **53**, 1110–1136 (2018).](http://paperpile.com/b/yjfVx4/NszP)

49\.	[Kroenke, C. H., Kubzansky, L. D., Schernhammer, E. S., Holmes, M. D. & Kawachi, I. Social networks, social support, and survival after breast cancer diagnosis. *J. Clin. Oncol.* **24**, 1105–1111 (2006).](http://paperpile.com/b/yjfVx4/qacn)

50\.	[Maunsell, E., Brisson, J. & Deschênes, L. Social support and survival among women with breast cancer. *Cancer* **76**, 631–637 (1995).](http://paperpile.com/b/yjfVx4/izwc)

51\.	[Schulz, R. & Beach, S. R. Caregiving as a risk factor for mortality: the Caregiver Health Effects Study. *JAMA* **282**, 2215–2219 (1999).](http://paperpile.com/b/yjfVx4/BTQg)

52\.	[Hovy, D. & Prabhumoye, S. Five sources of bias in natural language processing. *Lang. Linguist. Compass* **15**, e12432 (2021).](http://paperpile.com/b/yjfVx4/vnxY)

53\.	[Johnson, A., Pollard, T. & Mark, R. MIMIC-III clinical database. (2023) doi:](http://paperpile.com/b/yjfVx4/43rQc)[10.13026/C2XW26](http://dx.doi.org/10.13026/C2XW26)[.](http://paperpile.com/b/yjfVx4/43rQc)
54\.	[Johnson, A. E. W. *et al.* MIMIC-III, a freely accessible critical care database. *Sci Data* **3**, 160035 (2016).](http://paperpile.com/b/yjfVx4/l1GSM)

55\.	[Eyre, H. *et al.* Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python. *AMIA Annu. Symp. Proc.* **2021**, 438–447 (2021).](http://paperpile.com/b/yjfVx4/nDjDz)

56\.	[MedspaCy . spaCy universe. *medspaCy*](http://paperpile.com/b/yjfVx4/W72ul) [https://spacy.io/universe/project/medspacy](https://spacy.io/universe/project/medspacy)[.](http://paperpile.com/b/yjfVx4/W72ul)
57\.	[Leitner, F. *syntok: Text tokenization and sentence segmentation (segtok v2)*. (Github).](http://paperpile.com/b/yjfVx4/Gjq4k)
58\.	[Multi-document annotation environment. *MAE*](http://paperpile.com/b/yjfVx4/P9XW) [https://keighrim.github.io/mae-annotation/](https://keighrim.github.io/mae-annotation/)[.](http://paperpile.com/b/yjfVx4/P9XW)
59\.	[OpenAI API.](http://paperpile.com/b/yjfVx4/aC6KA) [http://platform.openai.com](http://platform.openai.com)[.](http://paperpile.com/b/yjfVx4/aC6KA)
60\.	[Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. in *Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)* 4171–4186 (Association for Computational Linguistics, 2019).](http://paperpile.com/b/yjfVx4/ABnp)

61\.	[Chung, H. W. *et al.* Scaling Instruction-Finetuned Language Models. Preprint at](http://paperpile.com/b/yjfVx4/X5d6) https://arxiv.org/abs/2210.11416 [(2022).](http://paperpile.com/b/yjfVx4/X5d6)

62\.	[Longpre, S. *et al.* The Flan Collection: Designing Data and Methods for Effective Instruction Tuning. *arXiv \[cs.AI\]* (2023).](http://paperpile.com/b/yjfVx4/eb93)

63\.	[Hu, E. J. *et al.* LoRA: Low-Rank Adaptation of Large Language Models. Preprint at https://arxiv.org/abs/2106.09685 (2021).](http://paperpile.com/b/yjfVx4/xoIw)

64\.	[Kondrashchenko, I. *scikit-llm: Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks*. (Github).](http://paperpile.com/b/yjfVx4/yYPKc)
Supplementary Methods
**Annotation Details**

The most common type of disagreement between annotators involved one annotator labeling a sentence with a common tag (Support, Employment, and Relationship) and the other annotator not giving that sentence any label. For Employment and Relationship tags, this was most often due to  simple annotation errors that get resolved through the adjudication process without much discussion. There were some instances for Employment where the language was vague as to whether the patient was on a break from work due to their job or whether they were no longer employed, which was a source of disagreements. The Support tag was a more  conceptually complex tag resulting in disagreement. For example, there were disagreements based on whether a patient reporting feeling better because they had individuals visit their house, without details of the visit, consisted of support. Although it was still among the most prevalent of annotation disagreements, we believe the support tag’s complexity was minimized through pilot annotation rounds and guideline revisions. The disagreement types with \>5 instances are listed below:

**Disagreement type					Count**

NO\_SDOH, SUPPORT\_plus				27
NO\_SDOH, EMPLOYMENT\_employed		16
NO\_SDOH, RELATIONSHIP\_married		15
NO\_SDOH, PARENT					  8
NO\_SDOH SUPPORT\_minus			  6

**Hyper-parameters for model training**

During the model development, the fine-tuning process of the best-performing models follows specific hyper-parameters using two *Nvidia RTX 3090 GPUs*. A per-device training batch size of 32 is used along with a learning rate of 1e-3. The model is trained for a total of 3 epochs. Additionally, the LoRA configuration is employed with a rank 'r' of 16 and a 'lora\_alpha' value of 32\. This configuration targets the "q" and "v" modules in the transformer layers and incorporates a dropout rate of 0.05.

   per\_device\_train\_batch\_size=32,
   learning\_rate=1e-3,
   num\_train\_epochs=3,
	   lora\_config \= LoraConfig(
        r=16,
        lora\_alpha=32,
        target\_modules=\["q", "v"\],
        lora\_dropout=0.05,
        bias="none",
        task\_type=TaskType.SEQ\_2\_SEQ\_LM
    )

**Label resolution examples for sequence-to-sequence models**

	*Example 1:*

Source: “summarize: This is a patient with a history of heart disease.”
Target label: ‘\<NO\_SDOH\>’

	Output from model: “NO\_SD”
	Post-processed Output: \[“\<NO\_SDOH\>”\]

	*Example 2:*

Source: “summarize: The patient’s wife drives him to treatment every day.”
	Target label: ‘RELATIONSHIP,SUPPORT’

	Output from model: “RELAT,SUPPORT”
	Post-processed Output: \[“RELATIONSHIP”, “SUPPORT”\]

**Bootstrap Sampling Calculations Example**

1\. Set our desired precision level for standard error (SE) for the performance metric of macro-F1 to be \+/- 0.01

2\. Estimate variability by taking a small number of initial samples, e.g.:

* Take 100 initial bootstrap samples of size k \= 10,860 (full test set size) with replacement.

* Calculate the standard deviation (σ) of F1 scores across these 100 bootstraps across all model pairs between gold-only data and gold+augmented data.

* Let's say σ is estimated to be 0.03.

3\. Use the following formula to solve for n: SE \= σ/√n

* For example, say σ was estimated to be 0.03:

  * 0.01 \= 0.03/√n

  * n \= 9 \*100

* In practice, n varied from 2 to 34 across models, therefore we picked the largest (n=3400) for all comparison pairs.

4\. Therefore, the recommended numbers to achieve our desired SE for macro-F1:

* n \= 3400 (number of bootstrap samples)

* k \= 10,860 (size of each bootstrap sample)

We calculated the mean and 95% confidence intervals from the 3400 bootstrap samples, and compared the difference in macro-F1 when adding augmented data using the Mann-Whitney U-test.

We established our metric as Macro F1, and sampled to ensure that our SE on the 95% confidence interval limits was \< 0.01. Our selected bootstrap sample size matched the test-data size, sampling with replacement. We then computed the 5th and 95th percentile values for each of the calculated k samples from the resulting distributions. The standard deviation of these percentile values was subsequently determined to establish the precision of the confidence interval limits. For example, utilizing this methodological approach, a 95% confidence interval, accounting for a maximum variation of 5% and 95%, was ascertained to be 0.0091 for Table 3\. This was validated through the execution of bootstrapping, performed 3,400 times across three distinct samples.
Supplementary Tables
Table 1\.** Inter-annotator agreement for granular SDoH levels

| Granular SDoH Label | Class-wise Krippendorff's (α) |
| :---- | :---: |

| TRANSPORTATION\_distance | 0.00 |
| TRANSPORTATION\_resource | 0.67 |
| TRANSPORTATION\_other | 0.00 |
| HOUSING\_undomiciled | 0.00 |
| HOUSING\_poor | 0.29 |
| HOUSING\_other | 0.36 |
| RELATIONSHIP\_married | 0.95 |
| RELATIONSHIP\_partnered | 0.93 |
| RELATIONSHIP\_divorced | 0.86 |
| RELATIONSHIP\_widowed | 1.00 |
| RELATIONSHIP\_single | 0.84 |
| PARENT | 0.81 |
| EMPLOYMENT\_employed | 0.80 |
| EMPLOYMENT\_underemployed | 0.40 |
| EMPLOYMENT\_unemployed | 0.74 |
| EMPLOYMENT\_disability | 0.90 |
| EMPLOYMENT\_retired | 0.90 |
| EMPLOYMENT\_student | 1.00 |
| SUPPORT\_plus | 0.78 |
| SUPPORT\_minus | 0.74 |

SDoH \= social determinant of health.
Table 2\.** Inter-annotator agreement for higher-level SDoH mention labels

| Any SDoH Mention Label | Class-wise Krippendorff's (α) |
| :---- | :---: |

| SUPPORT | 0.77 |
| EMPLOYMENT | 0.89 |
| HOUSING | 0.71 |
| TRANSPORTATION | 0.64 |
| PARENT | 0.81 |
| RELATIONSHIP | 0.95 |

SDoH \= social determinant of health.
Table 3\.** Prompts used to generate synthetic SDoH sentences using GPT3.5

| Output Sentence Labela | Prompt |
| :---- | :---- |

| Housing-Adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of housing issues for patients: 1\. Pt came from Assisted Living Corp. and complained about rent increase.\\n2. “Pt came from Assisted Living Corp. and complained about rent increase.\\n3. He says he is worried about making his mortgage payments.\\n4. Pt is staying with a friend and does not have a mailing address.\\n5. Pt currently staying at Barbara McInnis shelter.\\n5. Pt is staying at the Motel for the time being, while on the waitlist for the Hope Lodge."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patient's housing issues similar to the examples."} |
| Transportation-Adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of transportation issues for patients: 1\. Pt lives 30mi away from hospital and complains about needing to transfer three times each way.\\n2. Pt missed appointment because her sister couldn't drive her today.\\n3. Pt is worried about making appointments because the metro is under construction this month.\\n4. Pt is worried about the two hour drive.\\n5. She is having trouble lying flat for treatment, she thinks it is because her back hurts after the two hour car ride into clinic.\\n6. Pt felt that coming to Los Angeles was hard for them and asked to be referred to Santa Cruz.\\n7. He is having trouble getting to and from the hospital."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patient's transportation issues similar to the examples."} |
| Relationship-Adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of divorced, widowed, single, separated issues for patients: 1\. Pt is meeting ex-wife at appointment.\\n2. Pt is married but separated.\\n3. Pt spouse passed away in October of last year.\\n4. Pt is single.\\n5. Pt arrived with his girlfriend, and his ex-wife will attend with him at next week’s session.\\n6. Pt has 3 kids from former marriage"},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patients being divorced, widowed, single, or separated issues similar to the examples."} |
| Relationship-Not adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of married/partnered sentences for patients: 1\. Pt and her husband came into my office today.\\n2. Pt and her fiancée came into my office today.\\n3. He is here with his boyfriend.\\n4. He is married to Sheila."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patients being married / partnered similar to the examples."} |
| Parent-Adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of parental status for patients: 1\. Pt has 2 children ages 9 and 13.\\n 2\. Pt has 2 teenage children.\\n3. Pt was seen today with his daughter Angela, 3 y/o for a routine checkup."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patients being a parent to minors similar to the examples."} |
| Employment-Adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of employment issues for patients: 1\. Pt works part-time at Jim's Fish and is struggling to pay rent.\\n2. Pt has been living off of unemployment for the past 2 months.\\n3. Used to be a car mechanic, but he has been on disability for the past 2 years since his diagnosis.\\n4. He is currently on disability and is also occasionally working as an Uber driver to help cover the bills."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patient's employment issues similar to the examples."} |
| Employment-Not adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of employment sentences for patients: 1\. Pt works as an electrician in Rockland.\\n2. Pt is a 75yr old retiree.\\n3. Pt is attending Cool University full time.\\n4. Pt is a semi-retired marketing consultant."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patient's employment similar to the examples."} |
| Social support-Adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of social support issues for patients: 1\. Pt lives alone.\\n2. Pt is struggling to find someone to watch his cat on the days he has to come for treatment."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patient's lack of social support similar to the examples."} |
| Social support-Not adverse |             {"role": "system", "content": "You are a physician."},             {"role": "user", "content": "Examples of social support sentences for patients: 1\. Here today is Pt, her daughter, and supportive wife.\\n2. Pt is living with his parents during treatment, while his neighbors watch his cat.\\n3. Pt had to borrow money from her friend to catch the bus today.\\n4. Pt is currently living with nephew while receiving treatment."},             {"role": "assistant", "content": "Ok I will remember that."},             {"role": "user", "content": "Imagine you are a physician. Please give me 100 sentences from your clinic notes about various patient's social support similar to the examples."} |

aOutput sentence label is the label assigned to all synthetic sentences generated from the prompt.
Table A4.** Z-Code to SDoH label mappings

| Z-Code | SDoH label mapping |
| :---- | :---- |

| Z55: Education and literacy | EDUCATION\_none |
| Z56: Employment and unemployment | EMPLOYMENT\_unemployed, EMPLOYMENT\_underemployed, EMPLOYMENT\_employed (with adverse work environment) |
| Z59: Housing and economic circumstances | HOUSING, SUPPORT\_minus, EMPLOYMENT\_un(der)employed |
| Z60: Social environment | SUPPORT\_minus |
| Z62: Upbringing | PARENT, SUPPORT\_minus |
| Z63: Other problems related to primary support group, including family circumstances | SUPPORT\_minus |
| Z75: Problems related to medical facilities and other health care | HOUSING, TRANSPORTATION |

SDoH \= social determinant of health.
Table 5\.** Ablation studies of removing gold-labeled sentences in training

| Any SDoH |  |  |  |  |  |  |  |  |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |

| **Percent undersampleda** | **Macro-F1** | **No SDoH** | **Employment** | **Housing** | **Parent** | **Relationship** | **Social Support** | **Transportation** |

| 10% |  |  |  |  |  |  |  |  |
| Gold data only | 0.586 | 0.996 | 0.745 | 0.333 | 0.000 | 0.947 | 0.484 | 0.600 |
| Gold \+ synthetic data | 0.654 | 0.996 | 0.809 | 0.600 | 0.452 | 0.919 | 0.566 | 0.235 |

| 25% |  |  |  |  |  |  |  |  |
| Gold data only | 0.638 | 0.997 | 0.750 | 0.571 | 0.160 | 0.969 | 0.516 | 0.500 |
| Gold \+ synthetic data | **0.659** | 0.996 | 0.822 | 0.545 | 0.452 | 0.938 | 0.571 | 0.286 |

| 40% |  |  |  |  |  |  |  |  |
| Gold data only | 0.534 | 0.995 | 0.719 | 0.000 | 0.087 | 0.932 | 0.604 | 0.400 |
| Gold \+ synthetic data | 0.638 | 0.996 | 0.810 | 0.667 | 0.400 | 0.956 | 0.455 | 0.182 |

| 50% |  |  |  |  |  |  |  |  |
| Gold data only | 0.500 | 0.995 | 0.683 | 0.000 | 0.083 | 0.957 | 0.559 | 0.222 |
| Gold \+ synthetic data | 0.686 | 0.996 | 0.824 | 0.750 | 0.465 | 0.935 | 0.629 | 0.200 |

| 70% |  |  |  |  |  |  |  |  |
| Gold data only | 0.449 | 0.995 | 0.657 | 0.000 | 0.167 | 0.900 | 0.425 | 0.000 |
| Gold \+ synthetic data | 0.607 | 0.994 | 0.720 | 0.545 | 0.400 | 0.825 | 0.429 | 0.333 |

| 75% |  |  |  |  |  |  |  |  |
| Gold data only | 0.493 | 0.996 | 0.746 | 0.000 | 0.240 | 0.933 | 0.533 | 0.000 |
| Gold \+ synthetic data | 0.596 | 0.995 | 0.782 | 0.500 | 0.074 | 0.886 | 0.537 | 0.400 |

| 90% |  |  |  |  |  |  |  |  |
| Gold data only | 0.183 | 0.988 | 0.000 | 0.000 | 0.000 | 0.259 | 0.031 | 0.000 |
| Gold \+ synthetic data | 0.505 | 0.994 | 0.733 | 0.400 | 0.143 | 0.849 | 0.108 | 0.308 |

| 100% |  |  |  |  |  |  |  |  |
| Gold data only | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |
| Gold \+ synthetic data | 0.063 | 0.000 | 0.047 | 0.017 | 0.228 | 0.036 | 0.095 | 0.015 |

| **Adverse SDoH** |  |  |  |  |  |  |  |  |

| **Percent undersampleda** | **Macro-F1** | **No SDoH** | **Employment** | **Housing** | **Parent** | **Relationship** | **Social Support** | **Transportation** |

| 10% |  |  |  |  |  |  |  |  |
| Gold data only | 0.535 | 0.997 | 0.746 | 0.400 | 0.083 | 0.933 | 0.143 | 0.444 |
| Gold \+ synthetic data | **0.671** | 0.997 | 0.719 | 0.750 | 0.474 | 0.921 | 0.375 | 0.462 |

| 25% |  |  |  |  |  |  |  |  |
| Gold data only | 0.548 | 0.997 | 0.643 | 0.571 | 0.000 | 0.881 | 0.143 | 0.600 |
| Gold \+ synthetic data | 0.646 | 0.997 | 0.716 | 0.667 | 0.378 | 0.879 | 0.353 | 0.533 |

| 40% |  |  |  |  |  |  |  |  |
| Gold data only | 0.565 | 0.998 | 0.730 | 0.000 | 0.410 | 0.933 | 0.286 | 0.600 |
| Gold \+ synthetic data | 0.578 | 0.997 | 0.635 | 0.545 | 0.400 | 0.903 | 0.300 | 0.267 |

| 50% |  |  |  |  |  |  |  |  |
| Gold data only | 0.471 | 0.997 | 0.688 | 0.571 | 0.000 | 0.755 | 0.000 | 0.286 |
| Gold \+ synthetic data | 0.641 | 0.997 | 0.690 | 0.667 | 0.313 | 0.921 | 0.400 | 0.500 |

| 70% |  |  |  |  |  |  |  |  |
| Gold data only | 0.408 | 0.997 | 0.500 | 0.000 | 0.160 | 0.808 | 0.143 | 0.250 |
| Gold \+ synthetic data | 0.566 | 0.997 | 0.646 | 0.600 | 0.389 | 0.929 | 0.154 | 0.250 |

| 75% |  |  |  |  |  |  |  |  |
| Gold data only | 0.309 | 0.996 | 0.256 | 0.000 | 0.000 | 0.410 | 0.000 | 0.500 |
| Gold \+ synthetic data | 0.534 | 0.996 | 0.480 | 0.545 | 0.294 | 0.866 | 0.273 | 0.286 |

| 90% |  |  |  |  |  |  |  |  |
| Gold data only | 0.142 | 0.995 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 |
| Gold \+ synthetic data | 0.426 | 0.996 | 0.311 | 0.462 | 0.160 | 0.747 | 0.143 | 0.167 |

| 100% |  |  |  |  |  |  |  |  |
| Gold data only | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 |
| Gold \+ synthetic data | 0.040 | 0.000 | 0.009 | 0.007 | 0.227 | 0.011 | 0.015 | 0.011 |

Settings: FlanXL, guideline synthetic data OR no synthetic data.
a% undersampled means percent taken away (e.g., 25% undersampled \= 25% of positive gold-labeled instances and 25% of negative gold-labeled instances removed).
SDoH \= social determinants of health.
Table 6\.** Most common discrepancies between ground-truth and best-performing model prediction for each task

| Task | Ground Truth | Model Prediction | Count |
| :---- | :---- | :---- | :---- |

| **Any SDoH Mention** | No SDoH | Support | 24 |

|  | No SDoH | Employment | 16 |
|  | Support | No SDoH | 10 |
| **Adverse SDoH Mention** | No SDoH | Employment | 12 |

|  | Parent | No SDoH | 10 |
|  | Employment | No SDoH | 6 |

SDoH \= social determinants of health.
Table 7\.** Confusion matrix for any SDoH mention gold label versus best-performing model prediction

|   |   | Gold Label |  |
| ----- | :---- | :---: | :---: |

|   |   | Positive | Negative |
| **Any SDoH Model Prediction** | Positive |  89 |  3 |

|  | Negative |  4 |  58 |

SDoH \= social determinants of health.
Table 8\.** Confusion matrix for adverse SDoH mention gold label versus best-performing model prediction

|   |   | Gold Label |  |
| ----- | :---- | :---: | :---: |

|   |   | Positive | Negative |
| **Adverse SDoH Model Prediction** | Positive |  45 |  13 |

|  | Negative |  3 |  93 |

SDoH \= social determinants of health.
Table 9\.** Confusion matrix for adverse SDoH gold label versus mapped Z-codes

|   |   | Gold Label |  |
| ----- | :---- | :---: | :---: |

|   |   | Positive | Negative |
| **Mapped Z-codes** | Positive | 1 |  5 |

|  | Negative |  47 |  101 |

SDoH \= social determinants of health.
Supplementary Figures

![][image22]

Figure 1\.** Class-wise and Macro-F1 scores of our best-performing model against mapped Z-Codes at the patient level (on test set and dev set).

![][image23]

Figure 2\.** Class-wise and Macro-F1 scores of our best-performing model against mapped Z-Codes at the patient level (on test set only).

[image19]: ../figures/image19.png
[image20]: ../figures/image20.png
[image21]: ../figures/image21.png
[image22]: ../figures/image22.png
[image23]: ../figures/image23.png
